---
date: 2019-07-23
title:  "Hello World av Hannah Fry – Kapitel 3, Justice"
---
I det tredje kapitlet tar Hannah Fry upp algoritmer som används i juridiska prövningar i allmänhet och det amerikanska rättssystemet i synnerhet.

Dagens juridiska system är belastat med en mängd svagheter. Där i finns bland annat rasism, sexism och olika förväntningar som finns på människor med olika bakgrund eller förutsättningar. Ett arv från den samhällskultur alla de som finns inom rättsväsendet fostrats i.

Därför är det inte svårt att förstå hur lockande det låter med en algoritm som dömmer och tolkar efter vad de tilltalade faktiskt sagt och gjort istället för utifrån deras kön, sexualitet eller sociala bakgrund. Sådana regelsystem och algoritmer finns redan inom olika delar av det juridiska systemet; på amerikansk federal nivå samt i Australien.

Men där konsekvens ligger i den ena vägskålen finner vi en annan typ av rättvisa i den andre. För där ökad konsekvens väger tungt vägs individuell prövning desto lättare.

Fry tar i kapitlet upp ett exempel där sådana algoritmer används i Virginia för att bedöma förbrytares risk att återgå i brottslighet. En riskfaktor som väger in när straffets storhet bedöms.

2003 dömdes Christopher Drew Brooks, 19 år gammal, för våldtäkt efter att ha haft en ömsesidig sexuell relation med en minderårig (14 år gammal) flickvän. Ett brott som brukligt ger mellan 7 och 16 månaders fängelse.

Men riskbedömningsalgoritmen rekommenderade att straffet höjdes upp till 24 månader. Detta kommer sig av att unga sexualförbrytare har större risk att återfalla i sexualbrott senare i livet. Hade Brooks istället varit 36 år gammal (och därmed 22 år äldre än flickan istället för 5 år) hade algoritmen rekommenderat att inget fängelsestraff alls dömdes ut.

Av alla algoritmens enskilda delar kan de tyckas både rättvisa och balancerade. Men tillsammans blir algoritmen svår att ha full insyn i. Och de enskilda omständigheterna som finns runt en brottslig handling faller helt ur beräkningen.

Det andra problemet med dessa algoritmer som Fry tar upp är, det till synes uppenbara faktumet, att de ärver de partiskheter och fördomar som råder hos de som bygger dem.

Det amerikanska samhällsmagasinet ProRepublica granskade 2016 ett liknande system (COMPAS) som det som användas i exemplet med Brooks ovan. Och fann avvikelser utifrån de tilltalades etniska tillhörighet. Detta trots att begreppet ”ras” eller ”etnicitet” inte finns med någonstans i algoritmen.

[https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing)

Utifrån det som brukar kallas för ”false positive vs false negative” så pekar Fry på hur det amerikanska samhällets politiska historia ärvs och förstärks in dessa juridiska algoritmer.

> ”The algoritm is judging them not on the color of there skin, but on the all-too-predictable consequences of America’s historically deeply imbalanced society.” – Hannah Fry

Samtidigt är inte Fry främmande för iden om att dessa algoritmer kan byggas på ett sätt som bryter detta sociala arv. Istället för att se deterministisk på dessa algoritmer som fasta monoliter kanske vi kan tänka på dem som verktyg för att nå det juridiska system vi vill ha, föreslår Fry.

Men då måste makten över dem flyttas ifrån stängda styrelserum och de lagar som skyddar privat egendom till ett demokratisk forum där vi med full insikt kan diskutera hur de skall utformas.